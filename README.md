# Neural-Networks-and-Optimization-Techniques
In this project, we explored various deep learning and optimization techniques for predicting house prices and understanding the behavior of neural networks. The focus was on comparing different architectures and optimization methods to improve model performance.

---

### Key Components:

1. **Linear Regression & Polynomial Regression**:
   - We started by comparing simple linear models to more complex polynomial regression models to observe how model complexity affects performance.

2. **Neural Networks with PyTorch**:
   - Built and trained neural networks with varying architectures (different numbers of hidden layers and neurons) and compared them to traditional linear models.
   - We experimented with **Stochastic Gradient Descent (SGD)**, **Adam optimizer**, and regularization techniques to improve the training process.

3. **Principal Component Analysis (PCA)**:
   - Applied **PCA** to reduce the dimensionality of our data, allowing us to visualize and analyze the key features influencing house price predictions.

4. **Training and Testing**:
   - We conducted extensive training with different learning rates and optimizers, analyzing the **training and validation losses** to ensure the models generalize well to unseen data.
   - **Test performance** was evaluated using metrics like **Mean Squared Error (MSE)** and **R-squared**, giving insight into the accuracy of our models.

---

### Conclusion:
Through this project, we demonstrated proficiency in using **PyTorch** to implement neural networks, optimize models using advanced techniques, and apply dimensionality reduction to improve performance.

---

### Group Members:
- **Sushanth Ravichandran**
- **Sankeerth Viswanadhuni**
